import streamlit as st
import pandas as pd
import os
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.vectorstores import FAISS
from langchain.tools.retriever import create_retriever_tool
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_community.embeddings import DashScopeEmbeddings
from langchain.chat_models import init_chat_model
from langchain_experimental.tools import PythonAstREPLTool
from langchain.callbacks.base import BaseCallbackHandler
from langchain_core.messages import HumanMessage, AIMessage
from typing import List
import matplotlib

matplotlib.use('Agg')
import os
from dotenv import load_dotenv

load_dotenv(override=True)

DeepSeek_API_KEY = os.getenv("DEEPSEEK_API_KEY")
dashscope_api_key = os.getenv("dashscope_api_key")

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# è®°å¿†åº“ç›®å½•
MEMORY_DB_DIR = "mem_db"


# è‡ªå®šä¹‰æµå¼è¾“å‡ºå›è°ƒå¤„ç†å™¨
class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text + "â–Œ")

    def on_llm_end(self, response, **kwargs):
        self.container.markdown(self.text)


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="09 Agent",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    /* ä¸»é¢˜è‰²å½© */
    :root {
        --primary-color: #1f77b4;
        --secondary-color: #ff7f0e;
        --success-color: #2ca02c;
        --warning-color: #ff9800;
        --error-color: #d62728;
        --background-color: #f8f9fa;
    }

    /* éšè—é»˜è®¤çš„Streamlitæ ·å¼ */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}

    /* æ ‡é¢˜æ ·å¼ */
    .main-header {
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        margin-bottom: 2rem;
    }

    /* å¡ç‰‡æ ·å¼ */
    .info-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        margin: 1rem 0;
        border-left: 4px solid var(--primary-color);
    }

    .success-card {
        background: linear-gradient(135deg, #e8f5e8, #f0f8f0);
        border-left: 4px solid var(--success-color);
    }

    .warning-card {
        background: linear-gradient(135deg, #fff8e1, #fffbf0);
        border-left: 4px solid var(--warning-color);
    }

    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background: linear-gradient(45deg, #1f77b4, #2196F3);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.5rem 1rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 2px 8px rgba(31, 119, 180, 0.3);
    }

    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(31, 119, 180, 0.4);
    }

    /* Tabæ ·å¼ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 0.5rem;
    }

    .stTabs [data-baseweb="tab"] {
        height: 60px;
        background-color: white;
        border-radius: 8px;
        padding: 0 24px;
        font-weight: 600;
        border: 2px solid transparent;
        transition: all 0.3s ease;
    }

    .stTabs [aria-selected="true"] {
        background: linear-gradient(45deg, #1f77b4, #2196F3);
        color: white !important;
        border: 2px solid #1f77b4;
    }

    /* ä¾§è¾¹æ æ ·å¼ */
    .css-1d391kg {
        background: linear-gradient(180deg, #f8f9fa, #ffffff);
    }

    /* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ */
    .uploadedFile {
        background: #f8f9fa;
        border: 2px dashed #1f77b4;
        border-radius: 10px;
        padding: 1rem;
        text-align: center;
        margin: 1rem 0;
    }

    /* çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .status-indicator {
        display: inline-flex;
        align-items: center;
        gap: 0.5rem;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-weight: 600;
        font-size: 0.9rem;
    }

    .status-ready {
        background: #e8f5e8;
        color: #2ca02c;
        border: 1px solid #2ca02c;
    }

    .status-waiting {
        background: #fff8e1;
        color: #ff9800;
        border: 1px solid #ff9800;
    }
</style>
""", unsafe_allow_html=True)


# åˆå§‹åŒ–embeddings
@st.cache_resource
def init_embeddings():
    return DashScopeEmbeddings(
        model="text-embedding-v1",
        dashscope_api_key=dashscope_api_key
    )


# åˆå§‹åŒ–LLM
@st.cache_resource
def init_llm():
    return init_chat_model("deepseek-chat", model_provider="deepseek", api_key=DeepSeek_API_KEY)


# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
def init_session_state():
    if 'pdf_messages' not in st.session_state:
        st.session_state.pdf_messages = []
    if 'csv_messages' not in st.session_state:
        st.session_state.csv_messages = []
    if 'df' not in st.session_state:
        st.session_state.df = None
    # å¯¹è¯è®°å¿†çª—å£ï¼ˆæŒ‰è½®æ•°ï¼šuser+assistant ä¸ºä¸€è½®ï¼‰
    if 'pdf_history_pairs' not in st.session_state:
        st.session_state.pdf_history_pairs = 6
    if 'csv_history_pairs' not in st.session_state:
        st.session_state.csv_history_pairs = 6
    # é•¿æœŸè®°å¿†å¼€å…³ä¸æ£€ç´¢é…ç½®
    if 'enable_long_memory_pdf' not in st.session_state:
        st.session_state.enable_long_memory_pdf = True
    if 'enable_long_memory_csv' not in st.session_state:
        st.session_state.enable_long_memory_csv = True
    if 'memory_k_pdf' not in st.session_state:
        st.session_state.memory_k_pdf = 5
    if 'memory_k_csv' not in st.session_state:
        st.session_state.memory_k_csv = 5


def build_chat_history(messages: List[dict], max_pairs: int) -> List:
    """å°†ä¼šè¯ä¸­çš„å†å²æ–‡æœ¬æ¶ˆæ¯è½¬æ¢ä¸º LangChain æ¶ˆæ¯ï¼Œå¹¶æŒ‰çª—å£é™åˆ¶ã€‚

    - ä»…çº³å…¥ type == 'text' çš„æ¶ˆæ¯
    - æ’é™¤å½“å‰æœ€æ–°ä¸€æ¡ç”¨æˆ·è¾“å…¥ï¼ˆè¯¥æ¡ç”± input æä¾›ï¼‰
    - æŒ‰æœ€è¿‘ max_pairs è½®ï¼ˆçº¦ 2*max_pairs æ¡æ¶ˆæ¯ï¼‰æˆªæ–­
    """
    if max_pairs <= 0:
        return []

    text_messages = [m for m in messages if m.get("type") == "text"]
    # æ’é™¤å½“å‰ç”¨æˆ·æœ€æ–°è¾“å…¥ï¼ˆè°ƒç”¨æ–¹å·²å…ˆ append userï¼Œå†è°ƒç”¨å“åº”å‡½æ•°ï¼‰
    if text_messages and text_messages[-1].get("role") == "user":
        text_messages = text_messages[:-1]

    selected = text_messages[-2 * max_pairs:]
    lc_messages = []
    for m in selected:
        content = m.get("content", "")
        if m.get("role") == "user":
            lc_messages.append(HumanMessage(content=content))
        else:
            lc_messages.append(AIMessage(content=content))
    return lc_messages


def memory_db_exists():
    return os.path.exists(MEMORY_DB_DIR) and os.path.exists(os.path.join(MEMORY_DB_DIR, "index.faiss"))


def retrieve_memory(query: str, k: int) -> str:
    """ä»é•¿æœŸè®°å¿†å‘é‡åº“æ£€ç´¢ä¸å½“å‰æŸ¥è¯¢ç›¸å…³çš„è®°å¿†ç‰‡æ®µï¼Œæ‹¼æ¥ä¸ºä¸Šä¸‹æ–‡æ–‡æœ¬ã€‚"""
    if k <= 0 or not memory_db_exists():
        return ""
    embeddings = init_embeddings()
    store = FAISS.load_local(MEMORY_DB_DIR, embeddings, allow_dangerous_deserialization=True)
    retriever = store.as_retriever(search_kwargs={"k": k})
    docs = retriever.get_relevant_documents(query)
    if not docs:
        return ""
    joined = "\n".join([d.page_content for d in docs])
    return joined[:2000]


def add_memories(texts: List[str]):
    """å°†è‹¥å¹²è®°å¿†ç‰‡æ®µå†™å…¥å‘é‡åº“ã€‚æ¯ä¸ªç‰‡æ®µä½œä¸ºç‹¬ç«‹æ–‡æ¡£ã€‚"""
    clean_texts = [t.strip() for t in texts if isinstance(t, str) and t.strip()]
    if not clean_texts:
        return
    embeddings = init_embeddings()
    if memory_db_exists():
        store = FAISS.load_local(MEMORY_DB_DIR, embeddings, allow_dangerous_deserialization=True)
        store.add_texts(clean_texts)
        store.save_local(MEMORY_DB_DIR)
    else:
        store = FAISS.from_texts(clean_texts, embedding=embeddings)
        store.save_local(MEMORY_DB_DIR)


def extract_memory_snippets(llm, user_input: str, assistant_output: str) -> List[str]:
    """è°ƒç”¨ LLM ä»ä¸€è½®å¯¹è¯ä¸­æç‚¼å‡ºç®€æ´ã€ç¨³å®šçš„é•¿æœŸè®°å¿†ç‰‡æ®µï¼ˆä¸­æ–‡ï¼Œ1-3 æ¡ï¼‰ã€‚
    è‹¥æ— ç¨³å®šä¿¡æ¯åˆ™è¿”å›ç©ºåˆ—è¡¨ã€‚"""
    prompt = (
        "ä½ æ˜¯å¯¹è¯è®°å¿†æå–å™¨ã€‚åŸºäºä»¥ä¸‹ç”¨æˆ·è¾“å…¥ä¸åŠ©æ‰‹å›å¤ï¼Œæå–å¯é•¿æœŸå¤ç”¨çš„ç®€æ´äº‹å®æˆ–åå¥½ï¼Œä¸è¦åŒ…å«éšç§ã€‚\n"
        "- ä»¥ä¸­æ–‡çŸ­å¥è¾“å‡ºï¼Œæ¯æ¡ä¸€è¡Œï¼Œä¸è¦ç¼–å·ã€‚\n"
        "- ä»…åœ¨æœ‰æ˜ç¡®ã€ç¨³å®šäº‹å®æ—¶è¾“å‡ºï¼Œæœ€å¤š3æ¡ï¼›è‹¥æ— åˆ™è¾“å‡ºç©ºå­—ç¬¦ä¸²ã€‚\n\n"
        f"[ç”¨æˆ·]\n{user_input}\n\n[åŠ©æ‰‹]\n{assistant_output}\n\n[è¾“å‡º]"
    )
    try:
        res = llm.invoke([HumanMessage(content=prompt)])
        text = getattr(res, "content", "") or str(res)
        lines = [ln.strip("â€¢- \t") for ln in text.splitlines()]
        return [ln for ln in lines if ln]
    except Exception:
        return []


# PDFå¤„ç†å‡½æ•°
def pdf_read(pdf_doc):
    text = ""
    for pdf in pdf_doc:
        pdf_reader = PdfReader(pdf)
        for page in pdf_reader.pages:
            text += page.extract_text()
    return text


def get_chunks(text):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = text_splitter.split_text(text)
    return chunks


def vector_store(text_chunks):
    embeddings = init_embeddings()
    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)
    vector_store.save_local("faiss_db")


def check_database_exists():
    return os.path.exists("faiss_db") and os.path.exists("faiss_db/index.faiss")


def get_pdf_response(user_question, message_placeholder):
    if not check_database_exists():
        return "âŒ è¯·å…ˆä¸Šä¼ PDFæ–‡ä»¶å¹¶ç‚¹å‡»'Submit & Process'æŒ‰é’®æ¥å¤„ç†æ–‡æ¡£ï¼"

    try:
        embeddings = init_embeddings()
        llm = init_llm()

        new_db = FAISS.load_local("faiss_db", embeddings, allow_dangerous_deserialization=True)
        retriever = new_db.as_retriever()

        memory_context = ""
        if st.session_state.enable_long_memory_pdf:
            memory_context = retrieve_memory(user_question, st.session_state.memory_k_pdf)

        prompt = ChatPromptTemplate.from_messages([
            ("system",
             """ä½ æ˜¯09 Agentï¼Œè¯·æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼Œç¡®ä¿æä¾›æ‰€æœ‰ç»†èŠ‚ï¼Œå¦‚æœç­”æ¡ˆä¸åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼Œè¯·è¯´"ç­”æ¡ˆä¸åœ¨ä¸Šä¸‹æ–‡ä¸­"ï¼Œä¸è¦æä¾›é”™è¯¯çš„ç­”æ¡ˆ"""),
            ("system", "ä»¥ä¸‹ä¸ºä½ çš„é•¿æœŸè®°å¿†ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰ï¼š\n{memory_context}"),
            ("placeholder", "{chat_history}"),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}"),
        ])

        retrieval_chain = create_retriever_tool(retriever, "pdf_extractor",
                                                "This tool is to give answer to queries from the pdf")

        # åˆ›å»ºæµå¼å¤„ç†å™¨
        stream_handler = StreamHandler(message_placeholder)

        agent = create_tool_calling_agent(llm, [retrieval_chain], prompt)
        agent_executor = AgentExecutor(agent=agent, tools=[retrieval_chain], verbose=True)

        chat_history = build_chat_history(st.session_state.pdf_messages, st.session_state.pdf_history_pairs)
        response = agent_executor.invoke(
            {"input": user_question, "chat_history": chat_history, "memory_context": memory_context},
            config={"callbacks": [stream_handler]}
        )
        output_text = response['output']

        # å¯¹è¯åæå–é•¿æœŸè®°å¿†å¹¶å†™å…¥
        if st.session_state.enable_long_memory_pdf:
            snippets = extract_memory_snippets(llm, user_question, output_text)
            add_memories(snippets)

        return output_text

    except Exception as e:
        return f"âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}"


# CSVå¤„ç†å‡½æ•°
def get_csv_response(query: str, message_placeholder):
    if st.session_state.df is None:
        return "è¯·å…ˆä¸Šä¼ CSVæ–‡ä»¶"

    llm = init_llm()
    locals_dict = {'df': st.session_state.df}
    tools = [PythonAstREPLTool(locals=locals_dict)]

    system = f"""Given a pandas dataframe `df` answer user's query.
    Here's the output of `df.head().to_markdown()` for your reference, you have access to full dataframe as `df`:
    ```
    {st.session_state.df.head().to_markdown()}
    ```
    Give final answer as soon as you have enough data, otherwise generate code using `df` and call required tool.
    If user asks you to make a graph, save it as `plot.png`, and output GRAPH:<graph title>.
    Example:
    ```
    plt.hist(df['Age'])
    plt.xlabel('Age')
    plt.ylabel('Count')
    plt.title('Age Histogram')
    plt.savefig('plot.png')
    ``` output: GRAPH:Age histogram
    Query:"""

    memory_context = ""
    if st.session_state.enable_long_memory_csv:
        memory_context = retrieve_memory(query, st.session_state.memory_k_csv)

    prompt = ChatPromptTemplate.from_messages([
        ("system", system),
        ("system", "ä»¥ä¸‹ä¸ºä½ çš„é•¿æœŸè®°å¿†ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰ï¼š\n{memory_context}"),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ])

    # åˆ›å»ºæµå¼å¤„ç†å™¨
    stream_handler = StreamHandler(message_placeholder)

    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

    chat_history = build_chat_history(st.session_state.csv_messages, st.session_state.csv_history_pairs)
    response = agent_executor.invoke(
        {"input": query, "chat_history": chat_history, "memory_context": memory_context},
        config={"callbacks": [stream_handler]}
    )
    output_text = response['output']

    if st.session_state.enable_long_memory_csv:
        snippets = extract_memory_snippets(llm, query, output_text)
        add_memories(snippets)

    return output_text


def main():
    init_session_state()

    # ä¸»æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ¤– 09 Agent </h1>', unsafe_allow_html=True)
    st.markdown(
        '<div style="text-align: center; margin-bottom: 2rem; color: #666;">PDFé—®ç­” & æ•°æ®åˆ†æ</div>',
        unsafe_allow_html=True)

    # åˆ›å»ºä¸¤ä¸ªä¸»è¦åŠŸèƒ½çš„æ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs(["ğŸ“„ PDFæ™ºèƒ½é—®ç­”", "ğŸ“Š CSVæ•°æ®åˆ†æ"])

    # PDFé—®ç­”æ¨¡å—
    with tab1:
        col1, col2 = st.columns([2, 1])

        with col1:
            st.markdown("### ğŸ’¬ ä¸PDFæ–‡æ¡£å¯¹è¯")

            # æ˜¾ç¤ºæ•°æ®åº“çŠ¶æ€
            if check_database_exists():
                st.markdown(
                    '<div class="info-card success-card"><span class="status-indicator status-ready">âœ… PDFæ•°æ®åº“å·²å‡†å¤‡å°±ç»ª</span></div>',
                    unsafe_allow_html=True)
            else:
                st.markdown(
                    '<div class="info-card warning-card"><span class="status-indicator status-waiting">âš ï¸ è¯·å…ˆä¸Šä¼ å¹¶å¤„ç†PDFæ–‡ä»¶</span></div>',
                    unsafe_allow_html=True)

            chat_container = st.container()

            with chat_container:
                # èŠå¤©ç•Œé¢
                for message in st.session_state.pdf_messages:
                    with st.chat_message(message["role"]):
                        if message["type"] == "text":
                            st.markdown(message["content"])
                        elif message["type"] == "streaming":
                            # å¯¹äºæµå¼æ¶ˆæ¯ï¼Œç›´æ¥æ˜¾ç¤ºæœ€ç»ˆå†…å®¹
                            st.markdown(message["content"])

            # ç”¨æˆ·è¾“å…¥
            if pdf_query := st.chat_input("ğŸ’­ å‘PDFæé—®...", disabled=not check_database_exists(), key="pdf_input"):
                st.session_state.pdf_messages.append({"role": "user", "content": pdf_query, "type": "text"})
                with st.chat_message("user"):
                    st.markdown(pdf_query)

                with st.chat_message("assistant"):
                    # åˆ›å»ºæ¶ˆæ¯å ä½ç¬¦ç”¨äºæµå¼è¾“å‡º
                    message_placeholder = st.empty()

                    with st.spinner("ğŸ¤” AIæ­£åœ¨åˆ†ææ–‡æ¡£..."):
                        response = get_pdf_response(pdf_query, message_placeholder)

                    # ç¡®ä¿æœ€ç»ˆå†…å®¹æ­£ç¡®æ˜¾ç¤º
                    message_placeholder.markdown(response)
                    st.session_state.pdf_messages.append({"role": "assistant", "content": response, "type": "text"})
                st.rerun()
        with col2:
            st.markdown("### ğŸ“ æ–‡æ¡£ç®¡ç†")
            st.slider("å¯¹è¯è®°å¿†çª—å£(è½®æ•°)", min_value=0, max_value=20, value=st.session_state.pdf_history_pairs,
                      key="pdf_history_pairs")
            st.checkbox("å¯ç”¨é•¿æœŸè®°å¿†", value=st.session_state.enable_long_memory_pdf, key="enable_long_memory_pdf")
            st.slider("é•¿æœŸè®°å¿†æ£€ç´¢æ¡ç›®æ•°", min_value=0, max_value=20, value=st.session_state.memory_k_pdf, key="memory_k_pdf")

            # æ–‡ä»¶ä¸Šä¼ 
            pdf_docs = st.file_uploader(
                "ğŸ“ ä¸Šä¼ PDFæ–‡ä»¶",
                accept_multiple_files=True,
                type=['pdf'],
                help="æ”¯æŒä¸Šä¼ å¤šä¸ªPDFæ–‡ä»¶",
                key="pdf_uploader"
            )

            if pdf_docs:
                st.success(f"ğŸ“„ å·²é€‰æ‹© {len(pdf_docs)} ä¸ªæ–‡ä»¶")
                for i, pdf in enumerate(pdf_docs, 1):
                    st.write(f"â€¢ {pdf.name}")

            # å¤„ç†æŒ‰é’®
            if st.button("ğŸš€ ä¸Šä¼ å¹¶å¤„ç†PDFæ–‡æ¡£", disabled=not pdf_docs, use_container_width=True, key="process_pdf"):
                with st.spinner("ğŸ“Š æ­£åœ¨å¤„ç†PDFæ–‡ä»¶..."):
                    try:
                        raw_text = pdf_read(pdf_docs)
                        if not raw_text.strip():
                            st.error("âŒ æ— æ³•ä»PDFä¸­æå–æ–‡æœ¬")
                            return

                        text_chunks = get_chunks(raw_text)
                        st.info(f"ğŸ“ æ–‡æœ¬å·²åˆ†å‰²ä¸º {len(text_chunks)} ä¸ªç‰‡æ®µ")

                        vector_store(text_chunks)
                        st.success("âœ… PDFå¤„ç†å®Œæˆï¼")
                        st.balloons()
                        st.rerun()

                    except Exception as e:
                        st.error(f"âŒ å¤„ç†PDFæ—¶å‡ºé”™: {str(e)}")

            # æ¸…é™¤æ•°æ®åº“
            if st.button("ğŸ—‘ï¸ æ¸…é™¤PDFæ•°æ®åº“", use_container_width=True, key="clear_pdf"):
                try:
                    import shutil
                    if os.path.exists("faiss_db"):
                        shutil.rmtree("faiss_db")
                    st.session_state.pdf_messages = []
                    st.success("æ•°æ®åº“å·²æ¸…é™¤")
                    st.rerun()
                except Exception as e:
                    st.error(f"æ¸…é™¤å¤±è´¥: {e}")

            # æ¸…é™¤é•¿æœŸè®°å¿†åº“
            if st.button("ğŸ—‘ï¸ æ¸…é™¤é•¿æœŸè®°å¿†åº“", use_container_width=True, key="clear_mem"):
                try:
                    import shutil
                    if os.path.exists(MEMORY_DB_DIR):
                        shutil.rmtree(MEMORY_DB_DIR)
                    st.success("é•¿æœŸè®°å¿†åº“å·²æ¸…é™¤")
                    st.rerun()
                except Exception as e:
                    st.error(f"æ¸…é™¤å¤±è´¥: {e}")

            # æ·»åŠ æ¸…é™¤èŠå¤©è®°å½•æŒ‰é’®
            if st.button("ğŸ—‘ï¸ æ¸…é™¤èŠå¤©è®°å½•", use_container_width=True, key="clear_pdf_chat"):
                st.session_state.pdf_messages = []
                st.success("èŠå¤©è®°å½•å·²æ¸…é™¤")
                st.rerun()

    # CSVæ•°æ®åˆ†ææ¨¡å—
    with tab2:
        col1, col2 = st.columns([2, 1])

        with col1:
            st.markdown("### ğŸ“ˆ æ•°æ®åˆ†æå¯¹è¯")

            # æ˜¾ç¤ºæ•°æ®çŠ¶æ€
            if st.session_state.df is not None:
                st.markdown(
                    '<div class="info-card success-card"><span class="status-indicator status-ready">âœ… æ•°æ®å·²åŠ è½½å®Œæˆ</span></div>',
                    unsafe_allow_html=True)
            else:
                st.markdown(
                    '<div class="info-card warning-card"><span class="status-indicator status-waiting">âš ï¸ è¯·å…ˆä¸Šä¼ CSVæ–‡ä»¶</span></div>',
                    unsafe_allow_html=True)

            chat_container = st.container()
            with chat_container:
                # èŠå¤©ç•Œé¢
                for message in st.session_state.csv_messages:
                    with st.chat_message(message["role"]):
                        if message["type"] == "dataframe":
                            st.dataframe(message["content"])
                        elif message["type"] == "image":
                            st.write(message["content"])
                            if os.path.exists('plot.png'):
                                st.image('plot.png')
                        else:
                            st.markdown(message["content"])

            # ç”¨æˆ·è¾“å…¥
            if csv_query := st.chat_input("ğŸ“Š åˆ†ææ•°æ®...", disabled=st.session_state.df is None, key="csv_input"):
                st.session_state.csv_messages.append({"role": "user", "content": csv_query, "type": "text"})
                with st.chat_message("user"):
                    st.markdown(csv_query)

                with st.chat_message("assistant"):
                    # åˆ›å»ºæ¶ˆæ¯å ä½ç¬¦ç”¨äºæµå¼è¾“å‡º
                    message_placeholder = st.empty()

                    with st.spinner("ğŸ”„ æ­£åœ¨åˆ†ææ•°æ®..."):
                        response = get_csv_response(csv_query, message_placeholder)

                    # å¤„ç†ä¸åŒç±»å‹çš„å“åº”
                    if isinstance(response, pd.DataFrame):
                        message_placeholder.empty()  # æ¸…ç©ºæµå¼è¾“å‡º
                        st.dataframe(response)
                        st.session_state.csv_messages.append(
                            {"role": "assistant", "content": response, "type": "dataframe"})
                    elif "GRAPH" in str(response):
                        message_placeholder.empty()  # æ¸…ç©ºæµå¼è¾“å‡º
                        text = str(response)[str(response).find("GRAPH") + 6:]
                        st.write(text)
                        if os.path.exists('plot.png'):
                            st.image('plot.png')
                        st.session_state.csv_messages.append({"role": "assistant", "content": text, "type": "image"})
                    else:
                        # ç¡®ä¿æœ€ç»ˆæ–‡æœ¬æ­£ç¡®æ˜¾ç¤º
                        message_placeholder.markdown(response)
                        st.session_state.csv_messages.append({"role": "assistant", "content": response, "type": "text"})
                st.rerun()

        with col2:
            st.markdown("### ğŸ“Š æ•°æ®ç®¡ç†")
            st.slider("å¯¹è¯è®°å¿†çª—å£(è½®æ•°)", min_value=0, max_value=20, value=st.session_state.csv_history_pairs,
                      key="csv_history_pairs")
            st.checkbox("å¯ç”¨é•¿æœŸè®°å¿†", value=st.session_state.enable_long_memory_csv, key="enable_long_memory_csv")
            st.slider("é•¿æœŸè®°å¿†æ£€ç´¢æ¡ç›®æ•°", min_value=0, max_value=20, value=st.session_state.memory_k_csv, key="memory_k_csv")

            # CSVæ–‡ä»¶ä¸Šä¼ 
            csv_file = st.file_uploader("ğŸ“ˆ ä¸Šä¼ CSVæ–‡ä»¶", type='csv', key="csv_uploader")
            if csv_file:
                st.session_state.df = pd.read_csv(csv_file)
                st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ!")

                # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                with st.expander("ğŸ‘€ æ•°æ®é¢„è§ˆ", expanded=True):
                    st.dataframe(st.session_state.df.head())
                    st.write(f"ğŸ“ æ•°æ®ç»´åº¦: {st.session_state.df.shape[0]} è¡Œ Ã— {st.session_state.df.shape[1]} åˆ—")

            # æ•°æ®ä¿¡æ¯
            if st.session_state.df is not None:
                if st.button("ğŸ“‹ ä¸Šä¼ å¹¶æ˜¾ç¤ºæ•°æ®ä¿¡æ¯", use_container_width=True, key="show_info"):
                    with st.expander("ğŸ“Š æ•°æ®ç»Ÿè®¡ä¿¡æ¯", expanded=True):
                        st.write("**åŸºæœ¬ä¿¡æ¯:**")
                        st.text(f"è¡Œæ•°: {st.session_state.df.shape[0]}")
                        st.text(f"åˆ—æ•°: {st.session_state.df.shape[1]}")
                        st.write("**åˆ—å:**")
                        st.write(list(st.session_state.df.columns))
                        st.write("**æ•°æ®ç±»å‹:**")
                        dtype_info = pd.DataFrame({
                            'åˆ—å': st.session_state.df.columns,
                            'æ•°æ®ç±»å‹': [str(dtype) for dtype in st.session_state.df.dtypes]
                        })
                        st.dataframe(dtype_info, use_container_width=True)

            # æ¸…é™¤æ•°æ®
            if st.button("ğŸ—‘ï¸ æ¸…é™¤CSVæ•°æ®", use_container_width=True, key="clear_csv"):
                st.session_state.df = None
                st.session_state.csv_messages = []
                if os.path.exists('plot.png'):
                    os.remove('plot.png')
                st.success("æ•°æ®å·²æ¸…é™¤")
                st.rerun()

            # æ·»åŠ æ¸…é™¤èŠå¤©è®°å½•æŒ‰é’®
            if st.button("ğŸ—‘ï¸ æ¸…é™¤èŠå¤©è®°å½•", use_container_width=True, key="clear_csv_chat"):
                st.session_state.csv_messages = []
                st.success("èŠå¤©è®°å½•å·²æ¸…é™¤")
                st.rerun()

    # åº•éƒ¨ä¿¡æ¯
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("**ğŸ”§ æŠ€æœ¯æ ˆ:**")
        st.markdown("â€¢ LangChain â€¢ Streamlit â€¢ FAISS â€¢ DeepSeek")
    with col2:
        st.markdown("**âœ¨ åŠŸèƒ½ç‰¹è‰²:**")
        st.markdown("â€¢ PDFæ™ºèƒ½é—®ç­” â€¢ æ•°æ®å¯è§†åŒ–åˆ†æ")
    with col3:
        st.markdown("**ğŸ’¡ ä½¿ç”¨æç¤º:**")
        st.markdown("â€¢ æ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼  â€¢ å®æ—¶å¯¹è¯äº¤äº’")


if __name__ == "__main__":
    main()